{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import socket\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size:  11314\n",
      "Testing Dataset Size:  7532\n",
      "Number of Classes:  20\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = load_files('20news-bydate/20news-bydate-train', encoding='ISO-8859-1')\n",
    "newsgroups_test = load_files('20news-bydate/20news-bydate-test', encoding='ISO-8859-1')\n",
    "\n",
    "X_train, y_train = newsgroups_train.data, newsgroups_train.target\n",
    "X_test, y_test = newsgroups_test.data, newsgroups_test.target\n",
    "\n",
    "print('Training Dataset Size: ', len(X_train))\n",
    "print('Testing Dataset Size: ', len(X_test))\n",
    "print('Number of Classes: ', len(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data matrix: (11314, 10000)\n",
      "Shape of testing data matrix: (7532, 10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Shape of training data matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape of testing data matrix: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Euclidean Distance (Library):\n",
      "[[0.         1.4070392  1.40986424 ... 1.40024178 1.40427376 1.40965994]\n",
      " [1.4070392  0.         1.39454536 ... 1.40739661 1.40466696 1.39033527]\n",
      " [1.40986424 1.39454536 0.         ... 1.3929457  1.40160715 1.40360347]\n",
      " ...\n",
      " [1.40024178 1.40739661 1.3929457  ... 0.         1.40768531 1.4127773 ]\n",
      " [1.40427376 1.40466696 1.40160715 ... 1.40768531 0.         1.41167435]\n",
      " [1.40965994 1.39033527 1.40360347 ... 1.4127773  1.41167435 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "euclidean_dist_library = pairwise_distances(X_train_tfidf, metric='euclidean')\n",
    "print(f\"Pairwise Euclidean Distance (Library):\\n{euclidean_dist_library}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Euclidean Distance Matrix:\n",
      "[[0.00000000e+00 1.40703920e+00 1.40986424e+00 ... 1.40024178e+00\n",
      "  1.40427376e+00 1.40965994e+00]\n",
      " [1.40703920e+00 1.49011612e-08 1.39454536e+00 ... 1.40739661e+00\n",
      "  1.40466696e+00 1.39033527e+00]\n",
      " [1.40986424e+00 1.39454536e+00            nan ... 1.39294570e+00\n",
      "  1.40160715e+00 1.40360347e+00]\n",
      " ...\n",
      " [1.40024178e+00 1.40739661e+00 1.39294570e+00 ... 0.00000000e+00\n",
      "  1.40768531e+00 1.41277730e+00]\n",
      " [1.40427376e+00 1.40466696e+00 1.40160715e+00 ... 1.40768531e+00\n",
      "  0.00000000e+00 1.41167435e+00]\n",
      " [1.40965994e+00 1.39033527e+00 1.40360347e+00 ... 1.41277730e+00\n",
      "  1.41167435e+00 1.49011612e-08]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mg/w4cw2nc563q822jj2x4x_qqh0000gn/T/ipykernel_7907/3054068930.py:11: RuntimeWarning: invalid value encountered in sqrt\n",
      "  distance_matrix = np.sqrt(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance_matrix(X):\n",
    "    \"\"\"\n",
    "    Compute the pairwise Euclidean distance matrix using the efficient matrix formula.\n",
    "    \"\"\"\n",
    "    # Compute the squared magnitudes of all vectors\n",
    "    squared_norms = np.sum(X ** 2, axis=1, keepdims=True)  # Shape: (n_samples, 1)\n",
    "\n",
    "    # Compute the distance matrix using the formula\n",
    "    distance_matrix = np.sqrt(\n",
    "        squared_norms + squared_norms.T - 2 * np.dot(X, X.T)\n",
    "    )\n",
    "\n",
    "    # Ensure no negative values due to floating-point errors\n",
    "    distance_matrix = np.maximum(distance_matrix, 0)\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "# Convert sparse matrix to dense\n",
    "X_train_dense = X_train_tfidf.toarray()\n",
    "\n",
    "# Calculate the Euclidean distance matrix\n",
    "euclidean_dist_matrix = euclidean_distance_matrix(X_train_dense)\n",
    "\n",
    "print(f\"Pairwise Euclidean Distance Matrix:\\n{euclidean_dist_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhojjatk/mnist-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist.data, mnist.target.astype(int)  # `X` is the feature matrix, `y` are labels\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "X /= 255.0\n",
    "\n",
    "# Split the data into train, validation, and test sets (80/10/10)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training data shape: {X_train.shape}\")  # (56000, 784)\n",
    "print(f\"Validation data shape: {X_val.shape}\")  # (7000, 784)\n",
    "print(f\"Testing data shape: {X_test.shape}\")    # (7000, 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
