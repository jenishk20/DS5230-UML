{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73abebb9-d847-426e-a6f2-8ba9942e4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73629c7-0c57-4af3-b927-3df8a71968bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    return np.loadtxt(filename)\n",
    "\n",
    "def initialize_params(dataset,gaussians):\n",
    "    datapoints, dimensions = dataset.shape\n",
    "    minValue = dataset.min(axis = 0)\n",
    "    maxValue = dataset.max(axis = 0)\n",
    "    means = np.random.rand(gaussians,dimensions)*(maxValue-minValue) + minValue\n",
    "    covariances = np.array([np.eye(dimensions) for _ in range(gaussians)])\n",
    "    weights = np.ones(gaussians) / gaussians\n",
    "    return means, covariances, weights\n",
    "\n",
    "def multivariate_normal_pdf(x, mean, cov):\n",
    "    d = len(mean)\n",
    "    cov_det = np.linalg.det(cov)  \n",
    "    cov_inv = np.linalg.inv(cov) \n",
    "\n",
    "    norm_factor = (2 * np.pi) ** (d / 2) * np.sqrt(cov_det)\n",
    "    diff = x - mean\n",
    "    exponent = -0.5 * np.dot(diff.T, np.dot(cov_inv, diff))\n",
    "\n",
    "    return np.exp(exponent) / norm_factor\n",
    "\n",
    "\n",
    "def assigning_points_to_cluster(dataset,means,covariances,weights,gaussians):\n",
    "    datapoints = dataset.shape[0]\n",
    "    probabilities = np.zeros((datapoints,gaussians))\n",
    "    \n",
    "    for k in range(gaussians):\n",
    "        for i in range(datapoints):\n",
    "            probabilities[i, k] = weights[k] * multivariate_normal_pdf(dataset[i], means[k], covariances[k])\n",
    "    \n",
    "    probabilities /= probabilities.sum(axis=1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "def parameter_update(dataset, probabilities, gaussians):\n",
    "    n, d = dataset.shape\n",
    "    weights = probabilities.sum(axis=0) / n\n",
    "    means = np.dot(probabilities.T, dataset) / probabilities.sum(axis=0)[:, None]\n",
    "    covariances = np.zeros((gaussians, d, d))\n",
    "    for k in range(gaussians):\n",
    "        diff = dataset - means[k]\n",
    "        covariances[k] = np.dot(probabilities[:, k] * diff.T, diff) / probabilities[:, k].sum()\n",
    "    return means, covariances, weights\n",
    "\n",
    "def e_m_min_max(dataset, gaussians, max_iters=100, diff=1e-4):\n",
    "    means, covariances, weights = initialize_params(dataset, gaussians)\n",
    "    for i in range(max_iters):\n",
    "        probabilities = assigning_points_to_cluster(dataset, means, covariances, weights, gaussians)\n",
    "        new_means, new_covariances, new_weights = parameter_update(dataset, probabilities, gaussians)\n",
    "        if np.linalg.norm(new_means - means) < diff:\n",
    "            break\n",
    "        means, covariances, weights = new_means, new_covariances, new_weights\n",
    "    return means, covariances, weights\n",
    "\n",
    "\n",
    "dataset_2_gaussians = load_file('2gaussian.txt')\n",
    "dataset_3_gaussians = load_file('3gaussian.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c55acc-12cc-4b31-981e-d694d9cb9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Means:\n",
      "   Feature 1  Feature 2\n",
      "0   2.994346   3.052071\n",
      "1   7.013259   3.983198\n",
      "\n",
      "Estimated Covariances:\n",
      "\n",
      "Cluster 1 Covariance Matrix:\n",
      "   Feature 1  Feature 2\n",
      "0   1.010588   0.027153\n",
      "1   0.027153   2.937657\n",
      "\n",
      "Cluster 2 Covariance Matrix:\n",
      "   Feature 1  Feature 2\n",
      "0   0.974566   0.497361\n",
      "1   0.497361   1.001050\n",
      "\n",
      "Estimated Weights:\n",
      "   Cluster 1  Cluster 2\n",
      "0   0.334832   0.665168\n"
     ]
    }
   ],
   "source": [
    "means, covariances, weights = e_m_min_max(dataset_2_gaussians, 2)\n",
    "\n",
    "print(\"\\nEstimated Means:\")\n",
    "print(pd.DataFrame(means, columns=[f\"Feature {i+1}\" for i in range(means.shape[1])]))\n",
    "\n",
    "print(\"\\nEstimated Covariances:\")\n",
    "for i, cov in enumerate(covariances):\n",
    "    print(f\"\\nCluster {i+1} Covariance Matrix:\")\n",
    "    print(pd.DataFrame(cov, columns=[f\"Feature {j+1}\" for j in range(cov.shape[1])]))\n",
    "\n",
    "print(\"\\nEstimated Weights:\")\n",
    "print(pd.DataFrame(weights.reshape(1, -1), columns=[f\"Cluster {i+1}\" for i in range(len(weights))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bad08eb-8e61-4258-a24a-d8fa0af25120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Means:\n",
      "   Feature 1  Feature 2\n",
      "0   3.039438   3.047763\n",
      "1   5.011599   7.001357\n",
      "2   7.021508   4.015432\n",
      "\n",
      "Estimated Covariances:\n",
      "\n",
      "Cluster 1 Covariance Matrix:\n",
      "   Feature 1  Feature 2\n",
      "0   1.028306   0.026349\n",
      "1   0.026349   3.383231\n",
      "\n",
      "Cluster 2 Covariance Matrix:\n",
      "   Feature 1  Feature 2\n",
      "0   0.979872   0.185257\n",
      "1   0.185257   0.974699\n",
      "\n",
      "Cluster 3 Covariance Matrix:\n",
      "   Feature 1  Feature 2\n",
      "0   0.990504   0.500994\n",
      "1   0.500994   0.995653\n",
      "\n",
      "Estimated Weights:\n",
      "   Cluster 1  Cluster 2  Cluster 3\n",
      "0   0.205537    0.49602   0.298444\n"
     ]
    }
   ],
   "source": [
    "means, covariances, weights = e_m_min_max(dataset_3_gaussians, 3)\n",
    "\n",
    "print(\"\\nEstimated Means:\")\n",
    "print(pd.DataFrame(means, columns=[f\"Feature {i+1}\" for i in range(means.shape[1])]))\n",
    "\n",
    "print(\"\\nEstimated Covariances:\")\n",
    "for i, cov in enumerate(covariances):\n",
    "    print(f\"\\nCluster {i+1} Covariance Matrix:\")\n",
    "    print(pd.DataFrame(cov, columns=[f\"Feature {j+1}\" for j in range(cov.shape[1])]))\n",
    "\n",
    "print(\"\\nEstimated Weights:\")\n",
    "print(pd.DataFrame(weights.reshape(1, -1), columns=[f\"Cluster {i+1}\" for i in range(len(weights))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77624f-aeff-4191-bb95-9b15f07be3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
