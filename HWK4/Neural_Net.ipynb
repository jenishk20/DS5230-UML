{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 20NG dataset with 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', 'you', 'really', 'have', 'that', 'much', 'information', 'on', 'him', 'really', 'i', 'don', 't', 'know', 'you', 'tell', 'me', 'what', 'percentage', 'of', 'players', 'reach', 'or', 'exceed', 'their', 'mle', 's', 'in', 'their', 'rookie', 'season', 'we', 're', 'talking', 'about', '1993', 'you', 'know', 'if', 'that', 'were', 'your', 'purpose', 'maybe', 'offerman', 'spent', '1992', 'getting', 'acclimated', 'if', 'you', 'will', 'the', 'dodgers', 'as', 'a', 'team', 'paid', 'a', 'big', 'price', 'that', 'season', 'perhaps', 'they', 'will', 'reap', 'the', 'benefits', 'down', 'the', 'road', 'do', 'you', 'really', 'think', 'they', 'would', 'have', 'done', 'what', 'they', 'did', 'if', 'they', 'were', 'competing', 'for', 'a', 'pennant', 'for', 'a', 'stat', 'head', 'i', 'm', 'amazed', 'that', 'you', 'put', 'any', 'credence', 'in', 'spring', 'training', 'did', 'you', 'notice', 'who', 'he', 'got', 'those', '10', 'hits', 'off', 'of', 'or', 'are', 'you', 'going', 'to', 'tell', 'me', 'that', 'it', 'doesn', 't', 'make', 'a', 'difference', 'wait', 'a', 'minute', 'i', 'missed', 'something', 'here', 'first', 'forget', 'keith', 'mitchell', 'are', 'you', 'saying', 'that', 'a', 'kid', 'who', 'moves', 'from', 'aa', 'to', 'aaa', 'and', 'then', 'does', 'not', 'improve', 'would', 'have', 'been', 'better', 'off', 'making', 'a', 'direct', 'leap', 'to', 'the', 'majors', 'if', 'a', 'player', 'does', 'well', 'at', 'aa', 'and', 'then', 'does', 'not', 'improve', 'at', 'aaa', 'isn', 't', 'that', 'a', 'sign', 'that', 'maybe', 'he', 'doesn', 't', 'belong', 'in', 'the', 'bigs', 'now', 'keith', 'mitchell', 'as', 'i', 'recall', 'no', 'stat', 'books', 'handy', 'surprise', 'he', 'jumped', 'from', 'aa', 'to', 'atlanta', 'in', '1991', 'he', 'did', 'so', 'well', 'that', 'he', 'was', 'returned', 'to', 'the', 'minors', 'where', 'he', 'didn', 't', 'do', 'very', 'well', 'at', 'all', 'now', 'his', 'career', 'is', 'in', 'jeopardy', 'so', 'how', 'does', 'he', 'fit', 'in', 'with', 'your', 'point', 'good', 'mle', 's', 'in', 'aa', 'moved', 'him', 'right', 'to', 'the', 'big', 'club', 'now', 'he', 's', 'one', 'step', 'away', 'from', 'being', 'traded', 'or', 'moved', 'out', 'of', 'baseball', 'duh', 'well', 'i', 've', 'cast', 'my', 'lot', 'certainly', 'you', 'may', 'understand', 'better', 'how', 'good', 'lopez', 'is', 'and', 'i', 'may', 'overvalue', 'experience', 'but', 'neither', 'one', 'of', 'us', 'runs', 'a', 'baseball', 'team', 'the', 'beastmaster']\n"
     ]
    }
   ],
   "source": [
    "categories = ['sci.space', 'comp.graphics', 'rec.sport.baseball', 'sci.med', 'talk.politics.mideast']\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    return text.split()\n",
    "\n",
    "tokenized_texts = [preprocess_text(doc) for doc in newsgroups.data]\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe embeddings: 400000 words.\n",
      "[ 0.26688    0.39632    0.6169    -0.77451   -0.1039     0.26697\n",
      "  0.2788     0.30992    0.0054685 -0.085256   0.73602   -0.098432\n",
      "  0.5479    -0.030305   0.33479    0.14094   -0.0070003  0.32569\n",
      "  0.22902    0.46557   -0.19531    0.37491   -0.7139    -0.51775\n",
      "  0.77039    1.0881    -0.66011   -0.16234    0.9119     0.21046\n",
      "  0.047494   1.0019     1.1133     0.70094   -0.08696    0.47571\n",
      "  0.1636    -0.44469    0.4469    -0.93817    0.013101   0.085964\n",
      " -0.67456    0.49662   -0.037827  -0.11038   -0.28612    0.074606\n",
      " -0.31527   -0.093774  -0.57069    0.66865    0.45307   -0.34154\n",
      " -0.7166    -0.75273    0.075212   0.57903   -0.1191    -0.11379\n",
      " -0.10026    0.71341   -1.1574    -0.74026    0.40452    0.18023\n",
      "  0.21449    0.37638    0.11239   -0.53639   -0.025092   0.31886\n",
      " -0.25013   -0.63283   -0.011843   1.377      0.86013    0.20476\n",
      " -0.36815   -0.68874    0.53512   -0.46556    0.27389    0.4118\n",
      " -0.854     -0.046288   0.11304   -0.27326    0.15636   -0.20334\n",
      "  0.53586    0.59784    0.60469    0.13735    0.42232   -0.61279\n",
      " -0.38486    0.35842   -0.48464    0.30728  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "\n",
    "glove_embeddings = {}\n",
    "embedding_dim = 100\n",
    "\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=np.float32)\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "print(\"Loaded GloVe embeddings:\", len(glove_embeddings), \"words.\")\n",
    "print(glove_embeddings['hello'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a vocabulary mapping\n",
    "word_to_idx = {word: i+1 for i, word in enumerate(glove_embeddings.keys())}  # +1 to reserve index 0 for padding\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "\n",
    "# Step 2: Convert tokenized text to indices\n",
    "def doc_to_indices(doc, word_to_idx, max_len=50):\n",
    "    return [word_to_idx[word] for word in doc if word in word_to_idx][:max_len]\n",
    "\n",
    "indexed_texts = [doc_to_indices(doc, word_to_idx) for doc in tokenized_texts]\n",
    "\n",
    "# Step 3: Pad sequences to have equal length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "indexed_tensors = [torch.tensor(seq, dtype=torch.long) for seq in indexed_texts]\n",
    "padded_sequences = pad_sequence(indexed_tensors, batch_first=True, padding_value=0)  # Padding index 0\n",
    "\n",
    "# Convert labels to tensor\n",
    "labels = torch.tensor(newsgroups.target, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Step 1: Create embedding matrix\n",
    "vocab_size = len(word_to_idx) + 1  # +1 for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in word_to_idx.items():\n",
    "    if word in glove_embeddings:\n",
    "        embedding_matrix[i] = glove_embeddings[word]\n",
    "\n",
    "# Step 2: Create PyTorch embedding layer\n",
    "embedding_layer = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(100, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        x = self.fc(hidden[-1])\n",
    "        return self.softmax(x)\n",
    "\n",
    "hidden_dim = 256\n",
    "output_dim = len(categories)\n",
    "model = TextClassifier(embedding_layer, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3321\n",
      "Epoch 2, Loss: 1.6165\n",
      "Epoch 3, Loss: 1.6130\n",
      "Epoch 4, Loss: 1.4380\n",
      "Epoch 5, Loss: 1.3888\n",
      "Epoch 6, Loss: 1.5074\n",
      "Epoch 7, Loss: 1.1498\n",
      "Epoch 8, Loss: 1.3211\n",
      "Epoch 9, Loss: 1.3561\n",
      "Epoch 10, Loss: 1.4768\n",
      "Epoch 11, Loss: 1.2904\n",
      "Epoch 12, Loss: 1.1543\n",
      "Epoch 13, Loss: 0.9958\n",
      "Epoch 14, Loss: 1.0251\n",
      "Epoch 15, Loss: 0.9575\n",
      "Epoch 16, Loss: 1.0024\n",
      "Epoch 17, Loss: 1.0052\n",
      "Epoch 18, Loss: 0.9056\n",
      "Epoch 19, Loss: 0.9057\n",
      "Epoch 20, Loss: 1.1000\n",
      "Epoch 21, Loss: 0.9067\n",
      "Epoch 22, Loss: 0.9557\n",
      "Epoch 23, Loss: 1.0562\n",
      "Epoch 24, Loss: 0.9051\n",
      "Epoch 25, Loss: 1.1163\n",
      "Epoch 26, Loss: 0.9675\n",
      "Epoch 27, Loss: 1.0879\n",
      "Epoch 28, Loss: 0.9560\n",
      "Epoch 29, Loss: 1.0551\n",
      "Epoch 30, Loss: 0.9560\n",
      "Epoch 31, Loss: 0.9058\n",
      "Epoch 32, Loss: 0.9054\n",
      "Epoch 33, Loss: 0.9551\n",
      "Epoch 34, Loss: 1.0052\n",
      "Epoch 35, Loss: 1.0050\n",
      "Epoch 36, Loss: 0.9551\n",
      "Epoch 37, Loss: 1.0050\n",
      "Epoch 38, Loss: 0.9551\n",
      "Epoch 39, Loss: 1.0050\n",
      "Epoch 40, Loss: 0.9050\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data to DataLoader\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(padded_sequences, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1, Loss: 1.0049\n",
      "Fine-Tuning Epoch 2, Loss: 0.9549\n",
      "Fine-Tuning Epoch 3, Loss: 0.9549\n",
      "Fine-Tuning Epoch 4, Loss: 0.9049\n",
      "Fine-Tuning Epoch 5, Loss: 1.0049\n",
      "Fine-Tuning Epoch 6, Loss: 0.9049\n",
      "Fine-Tuning Epoch 7, Loss: 0.9549\n",
      "Fine-Tuning Epoch 8, Loss: 0.9049\n",
      "Fine-Tuning Epoch 9, Loss: 1.0049\n",
      "Fine-Tuning Epoch 10, Loss: 0.9549\n",
      "Fine-Tuning Epoch 11, Loss: 0.9549\n",
      "Fine-Tuning Epoch 12, Loss: 0.9549\n",
      "Fine-Tuning Epoch 13, Loss: 0.9549\n",
      "Fine-Tuning Epoch 14, Loss: 1.0548\n",
      "Fine-Tuning Epoch 15, Loss: 1.0049\n",
      "Fine-Tuning Epoch 16, Loss: 0.9549\n",
      "Fine-Tuning Epoch 17, Loss: 1.0050\n",
      "Fine-Tuning Epoch 18, Loss: 0.9549\n",
      "Fine-Tuning Epoch 19, Loss: 0.9549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     loss = criterion(outputs, y_batch)\n\u001b[32m     10\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFine-Tuning Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Northeastern/DS5230_backup/myenv/lib/python3.13/site-packages/torch/optim/adam.py:476\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    474\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    478\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.embedding.weight.requires_grad = True  # Unfreeze embeddings\n",
    "\n",
    "# Re-train with fine-tuned embeddings\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Fine-Tuning Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            outputs = model(x_batch)\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Get predicted class\n",
    "            correct += (predictions == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    \n",
    "    return correct / total  # Return accuracy as a fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Frozen GloVe Embeddings: 0.9488\n",
      "Accuracy After Fine-Tuning: 0.9488\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy before fine-tuning\n",
    "initial_accuracy = compute_accuracy(model, dataloader)\n",
    "print(f\"Accuracy with Frozen GloVe Embeddings: {initial_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Compute accuracy after fine-tuning\n",
    "fine_tuned_accuracy = compute_accuracy(model, dataloader)\n",
    "print(f\"Accuracy After Fine-Tuning: {fine_tuned_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
